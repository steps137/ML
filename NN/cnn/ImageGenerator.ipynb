{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d500d508",
   "metadata": {},
   "source": [
    "# Keras ImageDataGenerator\n",
    "\n",
    "The methods of image normalization using keras ImageDataGenerator are analyzed.\n",
    "\n",
    "## Download MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd73e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils    import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(X_trn, Y_trn), (X_tst, Y_tst) = mnist.load_data()\n",
    "\n",
    "# summarize dataset shape\n",
    "print('Train: images:', X_trn.shape, 'classes:', Y_trn.shape)\n",
    "print('Test : images:', X_tst.shape, 'classes:', Y_tst.shape)\n",
    "\n",
    "# summarize pixel values\n",
    "print(f\"Train:  min:{X_trn.min()}, max:{X_trn.max()} mean:{X_trn.mean():.1f}, std:{X_trn.std():.1f}\")\n",
    "print(f\"Test:   min:{X_tst.min()}, max:{X_tst.max()} mean:{X_tst.mean():.1f}, std:{X_tst.std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0389d7d",
   "metadata": {},
   "source": [
    "## Used ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f393cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (X_tst.shape[1], X_tst.shape[2], 1)\n",
    "\n",
    "def get_data(X,Y, batch_size):\n",
    "    X = X.reshape( (-1, ) +  IMAGE_SHAPE )\n",
    "    Y = to_categorical(Y)                               # one hot encode target values    \n",
    "    print(\"X:\",X.shape, \" Y:\",Y.shape)\n",
    "\n",
    "    gen =   ImageDataGenerator(\n",
    "                rescale = 1.0/255,                     # 0) X *= rescale\n",
    "        \n",
    "                #samplewise_center  = True,             # 1) Set each sample mean to 0 (False)\n",
    "                #samplewise_std_normalization  = True,  # 2) Divide each input by its std (False)                                                 \n",
    "        \n",
    "                featurewise_center = True,             # 3) Set input mean to 0 over the dataset\n",
    "                featurewise_std_normalization = True,  # 4) Divide inputs by std of the dataset, feature-wise (False)\n",
    "            )                             \n",
    "                                          \n",
    "    gen.fit(X)                                         # only for featurewise !!!\n",
    "    \n",
    "    gen_iter = gen.flow(X, Y, batch_size=batch_size)   # prepare an iterators to scale images    \n",
    "    \n",
    "    return gen_iter, gen\n",
    "\n",
    "gen_iter, gen = get_data(X_tst, Y_tst, 100)\n",
    "\n",
    "\n",
    "print(f\"gen     mean: {gen.mean}, std: {gen.std}\")\n",
    "print(f\"dataset mean: {(X_tst/255).mean():.4f}, std: {(X_tst/255).std():.4f}\\n\")\n",
    "\n",
    "batch_X, batch_Y = gen_iter.next()\n",
    "\n",
    "print('batches:', len(gen_iter), end=\"   \")                           # 10000/batch_size \n",
    "print(f'batch shape: {batch_X.shape}, min: {batch_X.min():.3f}, max:{batch_X.max():.3f}')\n",
    "print(f'batch mean: {batch_X.mean():.3f}')\n",
    "print(f'batch std : {batch_X.std():.3f}\\n')\n",
    "print('mean:', batch_X[0:8].mean( (1,2,3) ))\n",
    "print('std :', batch_X[0:8].std ( (1,2,3) ))\n",
    "if gen.mean is not None:\n",
    "    print('mean(x_f):', -gen.mean/gen.std,  'std(x_f):', 1./gen.std, \"(see below explanation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f1713",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- if using only **samplewise**, each image will have zero mean and unit variance\n",
    "- if using only **featurewise**, each image will have non zero mean and non unit variance, but on average the batch will be approximately normalized\n",
    "- if you use **samplewise + featurewise** at the same time, each image will be highly biased and have a large variance (if the entire dataset has not been normalized). Thus, their simultaneous use is impractical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c32c9a",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "https://github.com/keras-team/keras/blob/v2.9.0/keras/preprocessing/image.py \n",
    "\n",
    "Keras first calculates statistics for the entire dataset (fit function).  `x.shape = (N,C,W,H)`\n",
    "```\n",
    "fit(x):                                     # Fits the data generator to some sample data.\n",
    "    self.mean = np.mean(x, axis=(0, 2, 3))  # mean by each channel throughout the dataset       \n",
    "    self.std  = np.std (x, axis=(0, 2, 3))  # if there is only one channel, then it is mean(), std()\n",
    "```\n",
    "Next (samplewise) it nnormalizes each image by its mean and variance.<br>\n",
    "_After that_ (featurewise) normalizes the result by global statistics (and gets the offset values in each image !!!?)\n",
    "```\n",
    "standardize(x):                            # Applies the normalization configuration in-place to a batch of inputs.\n",
    "    if self.rescale:                       x *= self.rescale\n",
    "    if self.samplewise_center:             x -= np.mean(x, keepdims=True)  # to one image\n",
    "    if self.samplewise_std_normalization:  x /= (np.std(x, keepdims=True) + 1e-6)\n",
    "    if self.featurewise_center:            x -= self.mean\n",
    "    if self.featurewise_std_normalization: x /= (self.std + 1e-6)\n",
    "          \n",
    "batch_x[i] = self.image_data_generator.standardize(x)\n",
    "```\n",
    "\n",
    "Throughout the dataset:\n",
    "$$\n",
    "m_f = \\bar{x}_\\mathrm{dataset},~~~~\\sigma_f=\\mathrm{std}(x_\\mathrm{dataset})\n",
    "$$\n",
    "For each image $x$:\n",
    "$$\n",
    "x ~~~\\mapsto~~~x_s = \\frac{x-\\bar{x}}{\\sigma}\\sim\\mathcal{N}(0,1)~~~\\mapsto~~~   x_f  = \\frac{x_s - m_f}{\\sigma_f} \n",
    "~~~~\\Rightarrow~~~~~\n",
    "\\langle x_f \\rangle = -\\frac{m_f}{\\sigma_f},~~~~~~~~~~\\mathrm{std}(x_f)= \\frac{1}{\\sigma_f} \n",
    "$$\n",
    "\n",
    "In fact, the convolutional layer copes well with the bias (MNIST):\n",
    "```\n",
    "Test Accuracy: 98.720,  98.990   only rescale\n",
    "Test Accuracy: 98.990,  98.950   samplewise + featurewise\n",
    "Test Accuracy: 99.030,  98.900   samplewise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69235708",
   "metadata": {},
   "source": [
    "## Train MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Input\n",
    "\n",
    "iter_trn, gen_trn = get_data(X_trn, Y_trn, 64)\n",
    "iter_tst, gen_tst = get_data(X_tst, Y_tst, 64)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SHAPE))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(iter_trn, steps_per_epoch=len(iter_trn), epochs=5)         # fit model with generator\n",
    "_, acc = model.evaluate_generator(iter_tst, steps=len(iter_tst), verbose=0)      # evaluate model\n",
    "\n",
    "print('Test Accuracy: %.3f' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e2ca2",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_SHAPE = (X_tst.shape[1], X_tst.shape[2], 1)\n",
    "\n",
    "def plot_samples(X, cols = 10, rows = 2):            \n",
    "    plt.figure(figsize=(2*cols, 2*rows))     \n",
    "    num = min(cols*rows, len(X))\n",
    "    for i in range(num):\n",
    "        im = X[i]\n",
    "        mi, ma = im.min(), im.max()        \n",
    "        plt.subplot(rows, cols, i + 1)        \n",
    "        plt.imshow(im, cmap='gray', vmin=mi, vmax=ma)\n",
    "        plt.axis('off')        \n",
    "    plt.show()\n",
    "\n",
    "def get_data(X, Y, batch_size):\n",
    "    X = X.reshape( (-1, ) +  IMAGE_SHAPE )        \n",
    "\n",
    "    gen =   ImageDataGenerator(\n",
    "                rescale = 1.0/255,                     # X *= rescale\n",
    "        \n",
    "                samplewise_center  = True,             # Set each sample mean to 0 (False)\n",
    "                samplewise_std_normalization  = True,  # Divide each input by its std (False)                                                 \n",
    "\n",
    "                vertical_flip=True, \n",
    "                horizontal_flip=True,                                              \n",
    "                rotation_range=180.0, \n",
    "                brightness_range=(0.8,1.2)        \n",
    "            )                                                                           \n",
    "    \n",
    "    gen_iter = gen.flow(X, Y, batch_size=batch_size)   # prepare an iterators to scale images    \n",
    "    \n",
    "    return gen_iter, gen\n",
    "\n",
    "plot_samples(X_tst)\n",
    "\n",
    "gen_iter, gen = get_data(X_tst,Y_tst, 100)\n",
    "\n",
    "batch_X, batch_Y = gen_iter.next()\n",
    "\n",
    "print(\"augmentation\")\n",
    "plot_samples(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "946066d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 16, 16, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 1)         2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16, 16, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input\n",
    "\n",
    "x = Input(shape=(16,16,1))\n",
    "y = Conv2D(1, (1, 1), activation='relu')(x)\n",
    "          \n",
    "model = Model(inputs=x, outputs=y)\n",
    "model.summary()\n",
    "\n",
    "out = model( np.zeros( (16,16,1) ) )\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
