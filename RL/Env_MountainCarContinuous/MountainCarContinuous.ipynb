{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b7317c",
   "metadata": {},
   "source": [
    "# MountainCar Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3f9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "#np.random.seed(1)\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "print(env.\n",
    "#env.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "874fb2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space:  (2,) float32\n",
      "low:    [-1.2  -0.07]\n",
      "high:   [0.6  0.07]\n",
      "actions: Box([-1.], [1.], (1,), float32)\n",
      "actions: (1,)\n"
     ]
    }
   ],
   "source": [
    "space = env.observation_space                     # observation space\n",
    "print(\"space: \", space.shape, space.dtype)        # space dimension and type\n",
    "print(\"low:   \", space.low)                       # minimum values\n",
    "print(\"high:  \", space.high)                      # maximum values\n",
    "\n",
    "actions = env.action_space                        # action space\n",
    "print(\"actions:\", actions)       # number of actions, type\n",
    "print(\"actions:\", actions.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62655bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZhiqingXiao\n",
    "# https://github.com/ZhiqingXiao/OpenAIGymSolution/tree/master/MountainCarContinuous-v0\n",
    "def policy(obs):\n",
    "    p, v = obs\n",
    "    force = 2*int( p > -4*v or p < 13*v-0.6) - 1.0\n",
    "    return np.array([force,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98df967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(obs):    \n",
    "    force = 2*int( obs[1] > 0 ) - 1.0\n",
    "    return np.array([force,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c822e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(obs):        \n",
    "    return 2*np.random.random((1,))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1954c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, render=False, verbose=False):\n",
    "    observation = env.reset()\n",
    "    episode_reward = 0.\n",
    "    for step in itertools.count():\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = policy(observation)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    if verbose:\n",
    "        print('get {} rewards in {} steps'.format(\n",
    "                episode_reward, step + 1))\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddd04a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average episode rewards: 95.88 ± 0.84  [93.06, 97.58]\n"
     ]
    }
   ],
   "source": [
    "rews = [run_episode(env) for _ in range(1000)]\n",
    "print(f\"average episode rewards: {np.mean(rews):.2f} ± {np.std(rews):.2f}  [{np.min(rews):.2f}, {np.max(rews):.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "613b2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MountainCar best solution. Reward: -98.2  [-108...-83] std = 7\n",
      "2022-06-13 11:55:40.431447\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "state = torch.load('models/MountainCar_Policy_2_32_64_1.98.1.pt')  \n",
    "print(state['info'])\n",
    "print(state['date'])\n",
    "print(state['model'])\n",
    "\n",
    "nH = [32, 64]\n",
    "model = nn.Sequential(           \n",
    "           nn.Linear(2, nH[0]),    \n",
    "           nn.Sigmoid(),         \n",
    "           nn.Linear(nH[0], nH[1]),  \n",
    "           nn.Sigmoid(),         \n",
    "           nn.Linear(nH[1], 1),  \n",
    "           nn.Sigmoid() )      \n",
    "\n",
    "model.load_state_dict(state['state']) \n",
    "\n",
    "def policy(obs):\n",
    "    #obs =  -1. + 2.*(obs - env.observation_space.low)/(env.observation_space.high-env.observation_space.low)\n",
    "    with torch.no_grad():    \n",
    "        x = torch.tensor(obs, dtype=torch.float32)\n",
    "        y = model(x)                \n",
    "    #a = 1 if y > 0.5 else -1\n",
    "    #return np.array([a])            \n",
    "    return np.array([2*y-1])            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4f1ff",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90b92107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ActorModel(nn.Module):\n",
    "    \"\"\" Neural network for pi(a|s) \"\"\"\n",
    "    def __init__(self, nS, nA, hiddens):\n",
    "        super(ActorModel, self).__init__()\n",
    "        \n",
    "        neurons, layers = [nS] + hiddens, []        \n",
    "        for i in range(len(neurons)-1):\n",
    "            layers.append(nn.Linear(neurons[i], neurons[i+1]) )            \n",
    "            layers.append( nn.ReLU() )\n",
    "        self.base = nn.Sequential(*layers)\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(neurons[-1], nA),\n",
    "            nn.Tanh()                   # action in [-1...1]\n",
    "        )             \n",
    "        self.std = nn.Sequential(\n",
    "            nn.Linear(neurons[-1], nA),\n",
    "            nn.Softplus()               # std > 0\n",
    "        )         \n",
    "         \n",
    "        \n",
    "    def forward(self, x):\n",
    "        base = self.base(x)        \n",
    "        return self.mu(base), self.std(base)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4844516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "MountainCarContinuous-v0: Q-function, Reward:  286\n",
      "2022-07-27 20:26:47.089979\n",
      "{'env': 'MountainCarContinuous-v0', 'ticks': 1000, 'timeout': True, 'method': 'ac', 'gamma': 0.99, 'decays': 1, 'capacity': 10000, 'actor': [64, 64], 'critic': [512, 512], 'online': 1, 'update': -1, 'std_min': 0.01, 'std_max': 3, 'scale': True, 'optimizer': 'adam', 'batch_act': 1000, 'batch_cri': 1000, 'lm_act': 1e-06, 'lm_cri': 0.0001, 'beta': 0.01}\n",
      "ActorModel(\n",
      "  (base): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (std): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (1): Softplus(beta=1, threshold=20)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(obs):\n",
    "    \"\"\" to [-1...1] \"\"\"    \n",
    "    return -1. + 2.*(obs - env.observation_space.low )/(env.observation_space.high-env.observation_space.low )\n",
    "        \n",
    "def policy(state):\n",
    "    state = scale(state)\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    mu, std = actor( state )\n",
    "     \n",
    "    mu  = mu.data.cpu().numpy()\n",
    "    std = std.data.cpu().numpy()\n",
    "     \n",
    "    actions = np.random.normal(mu, std)\n",
    "        \n",
    "    return np.clip(actions, -1, 1)       \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "state = torch.load('models/MountainCarContinuous-v0.96.pt')  \n",
    "\n",
    "print(state['info'])\n",
    "print(state['date'])\n",
    "print(state['config'])\n",
    "print(state['actor'])\n",
    "\n",
    "actor = ActorModel(2, 1, state['config']['actor']) \n",
    "actor.to(device)\n",
    "actor.load_state_dict(state['actor_nn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbc8b3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "\n",
    "def render_frame(frame, text: str):\n",
    "    \"\"\"\n",
    "    Get frame with overwritten text:\n",
    "    \"\"\"\n",
    "    im = Image.fromarray(frame)\n",
    "    if text:        \n",
    "        drawer = ImageDraw.Draw(im)    \n",
    "        text_color = (255,255,255) if np.mean(im) < 128 else (0,0,0)\n",
    "        font = ImageFont.truetype(\"verdana.ttf\", 18)\n",
    "        drawer.text((10, 10), text, fill=text_color, font=font)        \n",
    "        font = ImageFont.truetype(\"verdana.ttf\", 14)\n",
    "        drawer.text((im.size[0]-100,im.size[1]-20), \"QuData.com\", fill=text_color, font=font)\n",
    "    return im\n",
    "\n",
    "\n",
    "frames, last = [], 0\n",
    "for episode in range(1, 11):\n",
    "    rew = 0\n",
    "    print(f\"\\repisode:{episode:2d}\", end=\"\")\n",
    "    s = env.reset()                        \n",
    "    for t in range(1000):       \n",
    "        a = policy(s)                 \n",
    "        s, r, done, _ = env.step(a) \n",
    "        rew += r\n",
    "        \n",
    "        if done:\n",
    "            last = rew\n",
    "\n",
    "        frame = env.render(mode='rgb_array') \n",
    "        frame = render_frame(frame, f\"{episode:2d}: Acrtor-Critic  <rew> =  95.9 ± 0.8 [93.1, 97.6]  {last:4.0f}\")        \n",
    "        frames.append(frame)\n",
    "    \n",
    "        if done:              \n",
    "            break                \n",
    "\n",
    "imageio.mimwrite(\"render.mp4\", frames, fps=60)            \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
