{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4283c800",
   "metadata": {},
   "source": [
    "# MountainCar\n",
    "\n",
    "Exploring the `MountainCar-v0` environment from the Open Gym \n",
    "\n",
    "## Import libraries and create an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d165f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym                                      # OpenAI Gym library\n",
    "env = gym.make('MountainCar-v0')                # create an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a1ee5",
   "metadata": {},
   "source": [
    "## Show initial state\n",
    "\n",
    "- On Windows, the render window will pop up on top of the browser only if it is not maximized to full screen (slightly **reduce the browser window**). \n",
    "- You can close the render window only by executing the command `env.close()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46416a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()                               # initial observation on the system\n",
    "\n",
    "print('obs:', obs) \n",
    "plt.imshow(env.render('rgb_array'))             # render the environment as image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55161be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()                                       # сlose render window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b460352",
   "metadata": {},
   "source": [
    "## Environment properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4229614",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = env.observation_space                     # observation space\n",
    "print(\"space: \", space.shape, space.dtype)        # space dimension and type\n",
    "print(\"low:   \", space.low)                       # minimum values\n",
    "print(\"high:  \", space.high)                      # maximum values\n",
    "\n",
    "actions = env.action_space                        # action space\n",
    "print(\"actions:\", actions.n, actions.dtype)       # number of actions, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()                                 # initial observation on the system\n",
    "for i in range(1000):                             # 1000 time steps\n",
    "    action = 2                                    # always right\n",
    "    obs, rew, done, _ = env.step(action)          # take action and get information\n",
    "    env.render()                                  # draw the environment\n",
    "env.close()                                       # сlose render window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edd21c",
   "metadata": {},
   "source": [
    "## Reward Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afa74ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state):\n",
    "    return 2*int(state[1] > 0)                    # push towards speed\n",
    "\n",
    "def run(ticks = 500):\n",
    "    tot_rew = 0                                   # total reward    \n",
    "    state = env.reset()                           # start state\n",
    "    for t in range(1,ticks+1):       \n",
    "        action = policy(state)                    # select action\n",
    "        state, rew, done, _ = env.step(action)    # get inforamtion    \n",
    "        tot_rew += rew         \n",
    "        if done:                                  # end of episode\n",
    "            break\n",
    "            \n",
    "    return tot_rew                                \n",
    "\n",
    "def statistics(episodes = 1000, ticks = 200):\n",
    "    rews = np.empty(episodes)                      # rewards in each episode \n",
    "    \n",
    "    for episode in range(episodes):                \n",
    "        rews[episode] = run()\n",
    "        \n",
    "    mean, std = rews.mean(), rews.std()            \n",
    "    print(f\"rew = {mean:.1f} ± {std/len(rews)**0.5 : .0f} [{rews.min():.0f}...{rews.max():.0f}] std = {std:.0f}\")\n",
    "    \n",
    "    return mean, std                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4545d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rew = -98.2 ±  0 [-108...-83] std = 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-98.2464, 7.318967621188115)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics(episodes=1000, ticks=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e22fd",
   "metadata": {},
   "source": [
    "## Save Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "411cae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "\n",
    "def render_frame(frame, text: str):\n",
    "    \"\"\"\n",
    "    Get frame with overwritten text:\n",
    "    \"\"\"\n",
    "    im = Image.fromarray(frame)\n",
    "    if text:        \n",
    "        drawer = ImageDraw.Draw(im)    \n",
    "        text_color = (255,255,255) if np.mean(im) < 128 else (0,0,0)\n",
    "        font = ImageFont.truetype(\"verdana.ttf\", 18)\n",
    "        drawer.text((10, 10), text, fill=text_color, font=font)        \n",
    "        font = ImageFont.truetype(\"verdana.ttf\", 14)\n",
    "        drawer.text((im.size[0]-100,im.size[1]-20), \"QuData.com\", fill=text_color, font=font)\n",
    "    return im\n",
    "\n",
    "\n",
    "frames, last = [], 0\n",
    "for episode in range(1, 11):\n",
    "    rew = 0\n",
    "    s = env.reset()                        \n",
    "    for it in range(10000):       \n",
    "        a = policy(s)                 \n",
    "        s, r, done, _ = env.step(a) \n",
    "        rew += r\n",
    "        \n",
    "        if done:\n",
    "            last = rew\n",
    "\n",
    "        frame = env.render(mode='rgb_array') \n",
    "        frame = render_frame(frame, f\"Episode: {episode:2d},  <reward> = -98.2  [-108...-83]   last: {last:4.0f}\")\n",
    "        frames.append(frame)\n",
    "    \n",
    "        if done:              \n",
    "            break                \n",
    "\n",
    "imageio.mimwrite(\"render.mp4\", frames, fps=60)            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83d1ec",
   "metadata": {},
   "source": [
    "## Best Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71771919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nH = [32, 64]\n",
    "model = nn.Sequential(           \n",
    "           nn.Linear(2, nH[0]),    \n",
    "           nn.Sigmoid(),         \n",
    "           nn.Linear(nH[0], nH[1]),  \n",
    "           nn.Sigmoid(),         \n",
    "           nn.Linear(nH[1], 1),  \n",
    "           nn.Sigmoid() )      \n",
    "\n",
    "state = torch.load('MountainCar_2_32_64_1.98.1.pt')  \n",
    "model.load_state_dict(state['model']) \n",
    "\n",
    "def policy(obs, level=0.05):\n",
    "    with torch.no_grad():    \n",
    "        x = torch.tensor(obs, dtype=torch.float32)\n",
    "        y = model(x)                \n",
    "    if y > 0.5 + level:\n",
    "        return 2\n",
    "    if y < 0.5 - level:\n",
    "        return 0            \n",
    "    return 1            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a569ac3",
   "metadata": {},
   "source": [
    "## Plotting of machine trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MountainCar:\n",
    "    def __init__(self, goal_velocity=0):\n",
    "        self.min_position  = -1.2\n",
    "        self.max_position  = 0.6\n",
    "        self.max_speed     = 0.07\n",
    "        self.goal_position = 0.5\n",
    "        self.goal_velocity = goal_velocity\n",
    "\n",
    "        self.low  = np.array([self.min_position, -self.max_speed], dtype=np.float32)\n",
    "        self.high = np.array([self.max_position,  self.max_speed], dtype=np.float32)\n",
    "\n",
    "        self.force   = 0.001\n",
    "        self.gravity = 0.0025        \n",
    "\n",
    "    def step(self, action: int):\n",
    "        position, velocity = self.state\n",
    "\n",
    "        velocity += (action - 1) * self.force + math.cos(3 * position) * (-self.gravity)\n",
    "        velocity = np.clip(velocity, -self.max_speed, self.max_speed)\n",
    "        position += velocity\n",
    "        position = np.clip(position, self.min_position, self.max_position)\n",
    "        if position == self.min_position and velocity < 0:\n",
    "            velocity = 0\n",
    "\n",
    "        done = bool(position >= self.goal_position and velocity >= self.goal_velocity)\n",
    "\n",
    "        self.state = (position, velocity)\n",
    "        return np.array(self.state, dtype=np.float32), done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e73166",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MountainCar()\n",
    "X, V = [], []\n",
    "\n",
    "m = -math.pi/6\n",
    "startX = np.array([    m, m,     m,      m,    m,   m, m,  m,  m])  #np.linspace(-0.6, 0.5, 10)\n",
    "startV = np.array([ 0.07, 0.06, 0.05,  0.04,  0.03, 0.02, -0.04, -0.05, -0.06])  #np.full( (len(startX),),  0.07)\n",
    "\n",
    "for i in range(len(startX)):\n",
    "    x, v = startX[i], startV[i]\n",
    "    X.append([])\n",
    "    V.append([])\n",
    "    X[-1].append(x)\n",
    "    V[-1].append(v)\n",
    "    env.state = (x, v)\n",
    "    for _ in range(200):\n",
    "        obs, done = env.step(1)     # сделать действие и получить информацию\n",
    "        x, v = obs\n",
    "        X[-1].append(x)\n",
    "        V[-1].append(v)\n",
    "        if done:\n",
    "            break\n",
    "        env.state = obs\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8)) \n",
    "plt.xlim(-1.2, 0.6)\n",
    "plt.ylim(-0.07, 0.07)\n",
    "plt.axhline(0, linestyle='--', c='black', linewidth=1)\n",
    "plt.axvline(0.5, linestyle='--', c='black', linewidth=1)\n",
    "plt.axvline(-math.pi/6, linestyle='--', c='black', linewidth=1)\n",
    "plt.xlabel(r'$x$',  {'fontsize': 16})  \n",
    "plt.ylabel(r'$v$',  {'fontsize': 16}) \n",
    "plt.title ('a=1',   {'fontsize': 16})\n",
    "\n",
    "for i in range(len(X)):\n",
    "    plt.plot    (X[i], V[i], linewidth=0.5)   \n",
    "    plt.scatter (X[i], V[i], s=10)  \n",
    "    plt.scatter (X[i][0], V[i][0], color=\"black\", s=30)  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115f45c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(frame, text = \"\"):\n",
    "    \"\"\" Get frame with overwritten text \"\"\"\n",
    "    im = Image.fromarray(frame)    \n",
    "    drawer = ImageDraw.Draw(im)    \n",
    "    text_color = (255,255,255) if np.mean(im) < 128 else (0,0,0)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 24)    \n",
    "    drawer.text((5, 5), text, fill=text_color, font=font)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 12)    \n",
    "    drawer.text(((im.size[0]-130, im.size[1]-16)), \"QuData.com\", fill=text_color, font=font)\n",
    "    return im\n",
    "\n",
    "def plt_to_array(fig):\n",
    "    \"\"\" Get array from figure of plt \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='raw')\n",
    "    buf.seek(0)\n",
    "    arr = np.reshape(np.frombuffer(buf.getvalue(), dtype=np.uint8),\n",
    "                     newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "    buf.close()    \n",
    "    return arr\n",
    "\n",
    "def add_frame(text):    \n",
    "    \"\"\" Add frame to frames list \"\"\"\n",
    "    fig = plt.figure(figsize=(16,4))    \n",
    "    for i in range(4):                    \n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.title (['LEFT <','DOWN v', 'RIGHT >',  'UP ^'][i]) \n",
    "        cmap =  ListedColormap([\"white\", \"gray\"])                  # \"Greys\"\n",
    "        sns.heatmap(Q[:, i].reshape(4,-1), annot=True, cbar=False, square=True, vmin=0, vmax=1., cmap=\"Greys\")\n",
    "\n",
    "    frames.append( draw_text( plt_to_array(fig), text) )\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
